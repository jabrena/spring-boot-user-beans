{
    "nodes": [
      {"id": "MDP", "group": "MDP"},
      {"id": "DP\nMethods", "group": "DP"},
      {"id": "Policy\nIteration", "group": "DP"},
      {"id": "Value\nIteration", "group": "DP"},
      {"id": "MC\nMethods", "group": "MC"},
      {"id": "Monte\nCarlo\nTD(1)", "group": "MC"},
      {"id": "TD\nMethods", "group": "TD"},
      {"id": "TD(0)", "group": "TD"},
      {"id": "n-Step\nBootstrap", "group": "TD"},
      {"id": "TD(λ)", "group": "TD"},
      {"id": "Forward\nView", "group": "TD"},
      {"id": "Eligibility\nTraces", "group": "TD"},
      {"id": "Backward\nView", "group": "TD"},
      {"id": "Value\nBased", "group": "Q"},
      {"id": "Sarsa", "group": "Sarsa"},
      {"id": "1-Step\nSarsa", "group": "Sarsa"},
      {"id": "n-Step\nSarsa", "group": "Sarsa"},
      {"id": "Sarsa(λ)", "group": "Sarsa"},
      {"id": "Expected\nSarsa", "group": "Sarsa"},
      {"id": "Q-Learning", "group": "Q"},
      {"id": "1-Step\nQ-Learning", "group": "Q"},
      {"id": "n-Step\nQ-Learning", "group": "Q"},
      {"id": "Q(λ)", "group": "Q"},
      {"id": "Double Q", "group": "Q"},
      {"id": "DQN", "group": "DQN"},
      {"id": "DDQN", "group": "DQN"},
      {"id": "Dueling-DQN", "group": "DQN"},
      {"id": "DRQN", "group": "DQN"},
      {"id": "C51\nDistributional\nDQN", "group": "DQN"},
      {"id": "Noisy Net", "group": "DQN"},
      {"id": "Rainbow\nDQN", "group": "DQN"},
      {"id": "Model", "group": "Model"},
      {"id": "Dyna-Q", "group": "Model"},
      {"id": "Dyna-Q+", "group": "Model"},
      {"id": "Policy\nGradients", "group": "PG"},
      {"id": "Reinforce", "group": "PG"},
      {"id": "Reinforce\nw/\nBaseline", "group": "PG"},
      {"id": "TRPO", "group": "PG"},
      {"id": "TRPO+", "group": "PG"},
      {"id": "PPO", "group": "PG"},
      {"id": "#None0", "group": "MA"},
      {"id": "#None1", "group": "None0"},
      {"id": "Intrinsic\nReward", "group": "Intrinsic"},
      {"id": "Curiosity\nICM", "group": "Intrinsic"},
      {"id": "Empowerment", "group": "Intrinsic"},
      {"id": "Actor-Critic", "group": "AC"},
      {"id": "A3C", "group": "AC"},
      {"id": "GA3C", "group": "AC"},
      {"id": "A2C", "group": "AC"},
      {"id": "PAAC", "group": "AC"},
      {"id": "ACER", "group": "AC"},
      {"id": "ACKTR", "group": "AC"},
      {"id": "DPG", "group": "AC"},
      {"id": "DDPG", "group": "AC"},
      {"id": "TD3", "group": "AC"},
      {"id": "SAC", "group": "AC"},
      {"id": "SAC w/\ntemperature\nauto-tune", "group": "AC"},
      {"id": "OAC", "group": "AC"},
      {"id": "Markov\nGame", "group": "MA"},
      {"id": "IQL", "group": "MA"},
      {"id": "IAC", "group": "MA"},
      {"id": "MADDPG", "group": "MA"},
      {"id": "Counterfactual\nReasoning", "group": "MA"},
      {"id": "Model of\nOther\nAgents", "group": "MA"},
      {"id": "Factorizable", "group": "MA"},
      {"id": "HyperNetwork", "group": "MA"},
      {"id": "COMA", "group": "MA"},
      {"id": "VDN", "group": "MA"},
      {"id": "QMIX", "group": "MA"},
      {"id": "QTRAN", "group": "MA"},
      {"id": "QTRAN-base", "group": "MA"},
      {"id": "QTRAN-alt", "group": "MA"},
      {"id": "Social\nInfluence", "group": "MA"}
    ],
    "links": [
      {"source": "MDP", "target": "DP\nMethods", "value": 1},
      {"source": "MDP", "target": "MC\nMethods", "value": 1},
      {"source": "MDP", "target": "TD\nMethods", "value": 1},
      {"source": "MDP", "target": "Markov\nGame", "value": 1},
      {"source": "DP\nMethods", "target": "Policy\nIteration", "value": 1},
      {"source": "DP\nMethods", "target": "Value\nIteration", "value": 1},
      {"source": "MC\nMethods", "target": "Monte\nCarlo\nTD(1)", "value": 1},
      {"source": "Monte\nCarlo\nTD(1)", "target": "Reinforce", "value": 1},
      {"source": "TD\nMethods", "target": "TD(0)", "value": 1},
      {"source": "TD\nMethods", "target": "n-Step\nBootstrap", "value": 1},
      {"source": "TD\nMethods", "target": "TD(λ)", "value": 1},
      {"source": "TD\nMethods", "target": "Monte\nCarlo\nTD(1)", "value": 1},
      {"source": "TD(λ)", "target": "Forward\nView", "value": 1},
      {"source": "TD(λ)", "target": "Backward\nView", "value": 1},
      {"source": "Eligibility\nTraces", "target": "Backward\nView", "value": 1},
      {"source": "Value\nBased", "target": "Sarsa", "value": 1},
      {"source": "Value\nBased", "target": "Q-Learning", "value": 1},
      {"source": "Sarsa", "target": "1-Step\nSarsa", "value": 1},
      {"source": "Sarsa", "target": "n-Step\nSarsa", "value": 1},
      {"source": "Sarsa", "target": "Sarsa(λ)", "value": 1},
      {"source": "Sarsa", "target": "Expected\nSarsa", "value": 1},
      {"source": "Q-Learning", "target": "1-Step\nQ-Learning", "value": 1},
      {"source": "Q-Learning", "target": "n-Step\nQ-Learning", "value": 1},
      {"source": "Q-Learning", "target": "Q(λ)", "value": 1},
      {"source": "Q-Learning", "target": "Double Q", "value": 1},
      {"source": "Q-Learning", "target": "Dyna-Q", "value": 1},
      {"source": "Q-Learning", "target": "DQN", "value": 1},
      {"source": "Q-Learning", "target": "A3C", "value": 1},
      {"source": "Double Q", "target": "DDQN", "value": 1},
      {"source": "TD(0)", "target": "1-Step\nSarsa", "value": 1},
      {"source": "TD(0)", "target": "1-Step\nQ-Learning", "value": 1},
      {"source": "n-Step\nBootstrap", "target": "n-Step\nSarsa", "value": 1},
      {"source": "n-Step\nBootstrap", "target": "n-Step\nQ-Learning", "value": 1},
      {"source": "TD(λ)", "target": "Sarsa(λ)", "value": 1},
      {"source": "TD(λ)", "target": "Q(λ)", "value": 1},
      {"source": "Model", "target": "Dyna-Q", "value": 1},
      {"source": "Dyna-Q", "target": "Dyna-Q+", "value": 1},
      {"source": "DQN", "target": "DDQN", "value": 1},
      {"source": "DQN", "target": "Dueling-DQN", "value": 1},
      {"source": "DQN", "target": "DDPG", "value": 1},
      {"source": "DQN", "target": "C51\nDistributional\nDQN", "value": 1},
      {"source": "DQN", "target": "DRQN", "value": 1},
      {"source": "DQN", "target": "Rainbow\nDQN", "value": 1},
      {"source": "DQN", "target": "Noisy Net", "value": 1},
      {"source": "DDQN", "target": "Rainbow\nDQN", "value": 1},
      {"source": "DDQN", "target": "Dueling-DQN", "value": 1},
      {"source": "Dueling-DQN", "target": "Rainbow\nDQN", "value": 1},
      {"source": "Dueling-DQN", "target": "Noisy Net", "value": 1},
      {"source": "C51\nDistributional\nDQN", "target": "Rainbow\nDQN", "value": 1},
      {"source": "Noisy Net", "target": "Rainbow\nDQN", "value": 1},
      {"source": "Policy\nGradients", "target": "Reinforce", "value": 1},
      {"source": "Policy\nGradients", "target": "TRPO", "value": 1},
      {"source": "TRPO", "target": "PPO", "value": 1},
      {"source": "TRPO", "target": "TRPO+", "value": 1},
      {"source": "TRPO", "target": "ACER", "value": 1},
      {"source": "TRPO", "target": "ACKTR", "value": 1},
      {"source": "TRPO", "target": "SAC", "value": 1},
      {"source": "PPO", "target": "TRPO+", "value": 1},
      {"source": "DPG", "target": "DDPG", "value": 1},
      {"source": "DDPG", "target": "TD3", "value": 1},
      {"source": "Reinforce", "target": "Reinforce\nw/\nBaseline", "value": 1},
      {"source": "Reinforce\nw/\nBaseline", "target": "A3C", "value": 1},
      {"source": "Actor-Critic", "target": "A3C", "value": 1},
      {"source": "Actor-Critic", "target": "DPG", "value": 1},
      {"source": "Actor-Critic", "target": "SAC", "value": 1},
      {"source": "Actor-Critic", "target": "OAC", "value": 1},
      {"source": "A3C", "target": "A2C", "value": 1},
      {"source": "A3C", "target": "GA3C", "value": 1},
      {"source": "A3C", "target": "ACER", "value": 1},
      {"source": "A3C", "target": "Noisy Net", "value": 1},
      {"source": "A3C", "target": "Curiosity\nICM", "value": 1},
      {"source": "A2C", "target": "PAAC", "value": 1},
      {"source": "A2C", "target": "ACKTR", "value": 1},
      {"source": "SAC", "target": "SAC w/\ntemperature\nauto-tune", "value": 1},
      {"source": "Markov\nGame", "target": "MADDPG", "value": 1},
      {"source": "Markov\nGame", "target": "IQL", "value": 1},
      {"source": "Markov\nGame", "target": "IAC", "value": 1},
      {"source": "Markov\nGame", "target": "COMA", "value": 1},
      {"source": "Markov\nGame", "target": "VDN", "value": 1},
      {"source": "Counterfactual\nReasoning", "target": "COMA", "value": 1},
      {"source": "Counterfactual\nReasoning", "target": "QTRAN", "value": 1},
      {"source": "Counterfactual\nReasoning", "target": "Social\nInfluence", "value": 1},
      {"source": "Model of\nOther\nAgents", "target": "Social\nInfluence", "value": 1},
      {"source": "Model of\nOther\nAgents", "target": "MADDPG", "value": 1},
      {"source": "Factorizable", "target": "VDN", "value": 1},
      {"source": "Factorizable", "target": "QMIX", "value": 1},
      {"source": "Factorizable", "target": "QTRAN", "value": 1},
      {"source": "HyperNetwork", "target": "QMIX", "value": 1},
      {"source": "VDN", "target": "QMIX", "value": 1},
      {"source": "QMIX", "target": "QTRAN", "value": 1},
      {"source": "QTRAN", "target": "QTRAN-base", "value": 1},
      {"source": "QTRAN", "target": "QTRAN-alt", "value": 1},
      {"source": "COMA", "target": "Social\nInfluence", "value": 1},
      {"source": "Intrinsic\nReward", "target": "Curiosity\nICM", "value": 1},
      {"source": "Intrinsic\nReward", "target": "Empowerment", "value": 1},
      {"source": "Empowerment", "target": "Social\nInfluence", "value": 1}
    ]
  }